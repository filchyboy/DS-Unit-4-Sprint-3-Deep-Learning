{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filchyboy/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ookhHMJZV-CP",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "- <a href=\"#p1\">Part 1:</a> Pre-Trained Model\n",
        "- <a href=\"#p2\">Part 2:</a> Custom CNN Model\n",
        "- <a href=\"#p3\">Part 3:</a> CNN with Data Augmentation\n",
        "\n",
        "\n",
        "You will apply three different CNN models to a binary image classification model using Keras. Classify images of Mountains (`./data/train/mountain/*`) and images of forests (`./data/train/forest/*`). Treat mountains as the positive class (1) and the forest images as the negative (zero). \n",
        "\n",
        "|Mountain (+)|Forest (-)|\n",
        "|---|---|\n",
        "|![](./data/train/mountain/art1131.jpg)|![](./data/validation/forest/cdmc317.jpg)|\n",
        "\n",
        "The problem is relatively difficult given that the sample is tiny: there are about 350 observations per class. This sample size might be something that you can expect with prototyping an image classification problem/solution at work. Get accustomed to evaluating several different possible models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jomOyz4qV-CS"
      },
      "source": [
        "# Pre - Trained Model\n",
        "<a id=\"p1\"></a>\n",
        "\n",
        "Load a pretrained network from Keras, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model # This is the functional API\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "```\n",
        "\n",
        "The `include_top` parameter in `ResNet50` will remove the full connected layers from the ResNet model. The next step is to turn off the training of the ResNet layers. We want to use the learned parameters without updating them in future training passes. \n",
        "\n",
        "```python\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "```\n",
        "\n",
        "Using the Keras functional API, we will need to additional additional full connected layers to our model. We we removed the top layers, we removed all preivous fully connected layers. In other words, we kept only the feature processing portions of our network. You can expert with additional layers beyond what's listed here. The `GlobalAveragePooling2D` layer functions as a really fancy flatten function by taking the average of each of the last convolutional layer outputs (which is two dimensional still). \n",
        "\n",
        "```python\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x) # This layer is a really fancy flatten\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(resnet.input, predictions)\n",
        "```\n",
        "\n",
        "Your assignment is to apply the transfer learning above to classify images of Mountains (`./data/train/mountain/*`) and images of forests (`./data/train/forest/*`). Treat mountains as the positive class (1) and the forest images as the negative (zero). \n",
        "\n",
        "Steps to complete assignment: \n",
        "1. Load in Image Data into numpy arrays (`X`) \n",
        "2. Create a `y` for the labels\n",
        "3. Train your model with pre-trained layers from resnet\n",
        "4. Report your model's accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMlkP9NxV-CT",
        "colab_type": "text"
      },
      "source": [
        "## Load in Data\n",
        "\n",
        "This surprisingly more difficult than it seems, because you are working with directories of images instead of a single file. This boiler plate will help you download a zipped version of the directory of images. The directory is organized into \"train\" and \"validation\" which you can use inside an `ImageGenerator` class to stream batches of images thru your model.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf0rOJ5zV-CT",
        "colab_type": "text"
      },
      "source": [
        "### Download & Summarize the Data\n",
        "\n",
        "This step is completed for you. Just run the cells and review the results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbr-3ywaV-CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "_URL = 'https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module2-convolutional-neural-networks/data.zip?raw=true'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('./data.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhJHIbxuV-CY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO0BHrxAxj9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1bc1323-cccb-4376-f7a1-92cb01e57170"
      },
      "source": [
        "train_dir"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/./data/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciDEwkEvV-Cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_mountain_dir = os.path.join(train_dir, 'mountain')  # directory with our training cat pictures\n",
        "train_forest_dir = os.path.join(train_dir, 'forest')  # directory with our training dog pictures\n",
        "validation_mountain_dir = os.path.join(validation_dir, 'mountain')  # directory with our validation cat pictures\n",
        "validation_forest_dir = os.path.join(validation_dir, 'forest')  # directory with our validation dog pictures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GgmDsHCV-Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_mountain_tr = len(os.listdir(train_mountain_dir))\n",
        "num_forest_tr = len(os.listdir(train_forest_dir))\n",
        "\n",
        "num_mountain_val = len(os.listdir(validation_mountain_dir))\n",
        "num_forest_val = len(os.listdir(validation_forest_dir))\n",
        "\n",
        "total_train = num_mountain_tr + num_forest_tr\n",
        "total_val = num_mountain_val + num_forest_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ8iGCVDV-Cl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6b6eaa72-fc44-4174-9571-50b4d1e7cdd5"
      },
      "source": [
        "print('total training mountain images:', num_mountain_tr)\n",
        "print('total training forest images:', num_forest_tr)\n",
        "\n",
        "print('total validation mountain images:', num_mountain_val)\n",
        "print('total validation forest images:', num_forest_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training mountain images: 254\n",
            "total training forest images: 270\n",
            "total validation mountain images: 125\n",
            "total validation forest images: 62\n",
            "--\n",
            "Total training images: 524\n",
            "Total validation images: 187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpD03JERV-Co",
        "colab_type": "text"
      },
      "source": [
        "### Keras `ImageGenerator` to Process the Data\n",
        "\n",
        "This step is completed for you, but please review the code. The `ImageGenerator` class reads in batches of data from a directory and pass them to the model one batch at a time. Just like large text files, this method is advantageous, because it stifles the need to load a bunch of images into memory. \n",
        "\n",
        "Check out the documentation for this class method: [Keras `ImageGenerator` Class](https://keras.io/preprocessing/image/#imagedatagenerator-class). You'll expand it's use in the third assignment objective."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR5jqwKKV-Cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "epochs = 10\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "CHNLS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EMlpwDHV-Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ3AjDTCV-Cw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8eed8a1e-9076-48d7-afb4-1890e808599e"
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 533 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSlrx8MV-Cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8df31a11-efcd-411a-e8a7-1acd69c6d336"
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 195 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKm4M7YseUi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8b2ace0-d99c-4f90-bcec-0b2be07066db"
      },
      "source": [
        "type(val_data_gen)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras_preprocessing.image.directory_iterator.DirectoryIterator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djshejFy_o55",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6626e3ee-44d2-4b38-dbdb-529a44a2b67b"
      },
      "source": [
        "val_data_gen[0]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[0.01176471, 0.41960788, 0.7607844 ],\n",
              "          [0.01568628, 0.42352945, 0.76470596],\n",
              "          [0.01568628, 0.42352945, 0.76470596],\n",
              "          ...,\n",
              "          [0.06666667, 0.47058827, 0.8313726 ],\n",
              "          [0.06666667, 0.47058827, 0.8313726 ],\n",
              "          [0.07450981, 0.4666667 , 0.8352942 ]],\n",
              " \n",
              "         [[0.01960784, 0.427451  , 0.7686275 ],\n",
              "          [0.01568628, 0.42352945, 0.76470596],\n",
              "          [0.01568628, 0.42352945, 0.76470596],\n",
              "          ...,\n",
              "          [0.07450981, 0.4784314 , 0.83921576],\n",
              "          [0.08235294, 0.47450984, 0.8431373 ],\n",
              "          [0.08235294, 0.47450984, 0.8431373 ]],\n",
              " \n",
              "         [[0.01568628, 0.43137258, 0.77647066],\n",
              "          [0.01568628, 0.43137258, 0.77647066],\n",
              "          [0.01568628, 0.43137258, 0.77647066],\n",
              "          ...,\n",
              "          [0.09019608, 0.48235297, 0.85098046],\n",
              "          [0.09019608, 0.48235297, 0.85098046],\n",
              "          [0.09019608, 0.48235297, 0.85098046]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.45098042, 0.25490198, 0.02352941],\n",
              "          [0.3372549 , 0.15294118, 0.        ],\n",
              "          [0.44705886, 0.28627452, 0.08235294],\n",
              "          ...,\n",
              "          [0.4039216 , 0.3803922 , 0.2784314 ],\n",
              "          [0.38823533, 0.37254903, 0.25882354],\n",
              "          [0.38431376, 0.3803922 , 0.2627451 ]],\n",
              " \n",
              "         [[0.50980395, 0.3137255 , 0.08235294],\n",
              "          [0.49803925, 0.30980393, 0.11764707],\n",
              "          [0.22352943, 0.0627451 , 0.        ],\n",
              "          ...,\n",
              "          [0.43137258, 0.4039216 , 0.29411766],\n",
              "          [0.4156863 , 0.4039216 , 0.28235295],\n",
              "          [0.39607847, 0.3921569 , 0.27058825]],\n",
              " \n",
              "         [[0.54509807, 0.34901962, 0.10196079],\n",
              "          [0.72156864, 0.5411765 , 0.34509805],\n",
              "          [0.5686275 , 0.4156863 , 0.25490198],\n",
              "          ...,\n",
              "          [0.41176474, 0.38431376, 0.27450982],\n",
              "          [0.4156863 , 0.4039216 , 0.28235295],\n",
              "          [0.38823533, 0.38431376, 0.2627451 ]]],\n",
              " \n",
              " \n",
              "        [[[0.01960784, 0.13333334, 0.29803923],\n",
              "          [0.01960784, 0.13333334, 0.29803923],\n",
              "          [0.01960784, 0.13333334, 0.29803923],\n",
              "          ...,\n",
              "          [0.01176471, 0.10196079, 0.27450982],\n",
              "          [0.01176471, 0.10196079, 0.27450982],\n",
              "          [0.01176471, 0.10196079, 0.27450982]],\n",
              " \n",
              "         [[0.02352941, 0.13725491, 0.3019608 ],\n",
              "          [0.02352941, 0.13725491, 0.3019608 ],\n",
              "          [0.02352941, 0.13725491, 0.3019608 ],\n",
              "          ...,\n",
              "          [0.01568628, 0.10588236, 0.2784314 ],\n",
              "          [0.01568628, 0.10588236, 0.2784314 ],\n",
              "          [0.01568628, 0.10588236, 0.2784314 ]],\n",
              " \n",
              "         [[0.02745098, 0.14117648, 0.30588236],\n",
              "          [0.02745098, 0.14117648, 0.30588236],\n",
              "          [0.02745098, 0.14117648, 0.30588236],\n",
              "          ...,\n",
              "          [0.01568628, 0.10588236, 0.2784314 ],\n",
              "          [0.01568628, 0.10588236, 0.2784314 ],\n",
              "          [0.01568628, 0.10588236, 0.2784314 ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.10980393, 0.00784314, 0.00392157],\n",
              "          [0.10980393, 0.00784314, 0.00392157],\n",
              "          [0.10980393, 0.00784314, 0.00392157],\n",
              "          ...,\n",
              "          [0.54901963, 0.5647059 , 0.6       ],\n",
              "          [0.6117647 , 0.61960787, 0.6666667 ],\n",
              "          [0.47450984, 0.48235297, 0.5294118 ]],\n",
              " \n",
              "         [[0.10980393, 0.00784314, 0.00392157],\n",
              "          [0.10980393, 0.00784314, 0.00392157],\n",
              "          [0.10980393, 0.00784314, 0.00392157],\n",
              "          ...,\n",
              "          [0.59607846, 0.60784316, 0.6431373 ],\n",
              "          [0.6666667 , 0.6745098 , 0.72156864],\n",
              "          [0.5647059 , 0.57254905, 0.61960787]],\n",
              " \n",
              "         [[0.10980393, 0.00784314, 0.00392157],\n",
              "          [0.10980393, 0.00784314, 0.00392157],\n",
              "          [0.10980393, 0.00784314, 0.00392157],\n",
              "          ...,\n",
              "          [0.61960787, 0.6313726 , 0.6666667 ],\n",
              "          [0.65882355, 0.6666667 , 0.7137255 ],\n",
              "          [0.60784316, 0.6156863 , 0.6627451 ]]],\n",
              " \n",
              " \n",
              "        [[[0.23137257, 0.27450982, 0.3921569 ],\n",
              "          [0.23529413, 0.2784314 , 0.39607847],\n",
              "          [0.23529413, 0.2784314 , 0.39607847],\n",
              "          ...,\n",
              "          [0.18431373, 0.21960786, 0.34117648],\n",
              "          [0.18431373, 0.21960786, 0.34117648],\n",
              "          [0.18431373, 0.21960786, 0.34117648]],\n",
              " \n",
              "         [[0.227451  , 0.27058825, 0.38823533],\n",
              "          [0.227451  , 0.27058825, 0.38823533],\n",
              "          [0.227451  , 0.27058825, 0.38823533],\n",
              "          ...,\n",
              "          [0.16862746, 0.20392159, 0.3254902 ],\n",
              "          [0.16862746, 0.20392159, 0.3254902 ],\n",
              "          [0.17254902, 0.20784315, 0.32941177]],\n",
              " \n",
              "         [[0.22352943, 0.26666668, 0.38431376],\n",
              "          [0.22352943, 0.26666668, 0.38431376],\n",
              "          [0.22352943, 0.26666668, 0.38431376],\n",
              "          ...,\n",
              "          [0.16470589, 0.20000002, 0.32156864],\n",
              "          [0.16470589, 0.20000002, 0.32156864],\n",
              "          [0.16078432, 0.19607845, 0.31764707]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.10196079, 0.09019608, 0.0627451 ],\n",
              "          [0.08627451, 0.07450981, 0.04705883],\n",
              "          [0.07450981, 0.05490196, 0.03137255],\n",
              "          ...,\n",
              "          [0.07450981, 0.03137255, 0.05490196],\n",
              "          [0.08235294, 0.03137255, 0.05882353],\n",
              "          [0.09411766, 0.03529412, 0.0627451 ]],\n",
              " \n",
              "         [[0.08235294, 0.07058824, 0.04313726],\n",
              "          [0.07058824, 0.05882353, 0.03137255],\n",
              "          [0.06666667, 0.04705883, 0.02352941],\n",
              "          ...,\n",
              "          [0.07450981, 0.03137255, 0.05490196],\n",
              "          [0.08627451, 0.02352941, 0.0627451 ],\n",
              "          [0.09411766, 0.02745098, 0.05882353]],\n",
              " \n",
              "         [[0.0627451 , 0.0509804 , 0.02352941],\n",
              "          [0.05490196, 0.04313726, 0.01568628],\n",
              "          [0.05882353, 0.04705883, 0.01960784],\n",
              "          ...,\n",
              "          [0.07058824, 0.02745098, 0.05882353],\n",
              "          [0.07450981, 0.02352941, 0.05882353],\n",
              "          [0.08627451, 0.01960784, 0.05882353]]],\n",
              " \n",
              " \n",
              "        ...,\n",
              " \n",
              " \n",
              "        [[[0.01568628, 0.16862746, 0.627451  ],\n",
              "          [0.01568628, 0.16862746, 0.627451  ],\n",
              "          [0.01176471, 0.16470589, 0.62352943],\n",
              "          ...,\n",
              "          [0.04313726, 0.20784315, 0.6392157 ],\n",
              "          [0.04705883, 0.21176472, 0.6509804 ],\n",
              "          [0.04705883, 0.21176472, 0.6509804 ]],\n",
              " \n",
              "         [[0.03529412, 0.18823531, 0.64705884],\n",
              "          [0.03137255, 0.18431373, 0.6431373 ],\n",
              "          [0.03137255, 0.18431373, 0.6431373 ],\n",
              "          ...,\n",
              "          [0.04313726, 0.20784315, 0.64705884],\n",
              "          [0.04705883, 0.21176472, 0.6509804 ],\n",
              "          [0.04705883, 0.21176472, 0.6509804 ]],\n",
              " \n",
              "         [[0.04313726, 0.19607845, 0.654902  ],\n",
              "          [0.04313726, 0.19607845, 0.654902  ],\n",
              "          [0.04313726, 0.19607845, 0.654902  ],\n",
              "          ...,\n",
              "          [0.04705883, 0.21176472, 0.6509804 ],\n",
              "          [0.04705883, 0.21176472, 0.6509804 ],\n",
              "          [0.0509804 , 0.21568629, 0.654902  ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.8588236 , 0.8470589 , 0.8745099 ],\n",
              "          [0.8588236 , 0.8470589 , 0.8745099 ],\n",
              "          [0.86274517, 0.85098046, 0.87843144],\n",
              "          ...,\n",
              "          [0.76470596, 0.76470596, 0.80392164],\n",
              "          [0.76470596, 0.77647066, 0.80392164],\n",
              "          [0.7843138 , 0.80392164, 0.82745105]],\n",
              " \n",
              "         [[0.85098046, 0.83921576, 0.86666673],\n",
              "          [0.854902  , 0.8431373 , 0.8705883 ],\n",
              "          [0.8588236 , 0.8470589 , 0.8745099 ],\n",
              "          ...,\n",
              "          [0.80392164, 0.81568635, 0.85098046],\n",
              "          [0.7960785 , 0.8078432 , 0.8352942 ],\n",
              "          [0.7725491 , 0.79215693, 0.81568635]],\n",
              " \n",
              "         [[0.854902  , 0.8431373 , 0.8705883 ],\n",
              "          [0.8588236 , 0.8470589 , 0.8745099 ],\n",
              "          [0.8588236 , 0.8470589 , 0.8745099 ],\n",
              "          ...,\n",
              "          [0.8078432 , 0.8196079 , 0.854902  ],\n",
              "          [0.7803922 , 0.8000001 , 0.8235295 ],\n",
              "          [0.7137255 , 0.73333335, 0.7568628 ]]],\n",
              " \n",
              " \n",
              "        [[[0.02745098, 0.02352941, 0.08627451],\n",
              "          [0.04313726, 0.03921569, 0.09411766],\n",
              "          [0.0509804 , 0.0509804 , 0.09803922],\n",
              "          ...,\n",
              "          [0.0509804 , 0.0509804 , 0.0509804 ],\n",
              "          [0.0509804 , 0.0509804 , 0.0509804 ],\n",
              "          [0.05490196, 0.05490196, 0.05490196]],\n",
              " \n",
              "         [[0.03921569, 0.03921569, 0.08627451],\n",
              "          [0.03529412, 0.03529412, 0.07450981],\n",
              "          [0.03529412, 0.03529412, 0.06666667],\n",
              "          ...,\n",
              "          [0.03921569, 0.03921569, 0.03921569],\n",
              "          [0.04313726, 0.04313726, 0.04313726],\n",
              "          [0.04705883, 0.04705883, 0.04705883]],\n",
              " \n",
              "         [[0.07058824, 0.07450981, 0.09411766],\n",
              "          [0.04313726, 0.04705883, 0.06666667],\n",
              "          [0.04313726, 0.04705883, 0.05490196],\n",
              "          ...,\n",
              "          [0.06666667, 0.06666667, 0.06666667],\n",
              "          [0.07058824, 0.07058824, 0.07058824],\n",
              "          [0.07450981, 0.07450981, 0.07450981]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.0627451 , 0.07450981, 0.03137255],\n",
              "          [0.19607845, 0.20784315, 0.16470589],\n",
              "          [0.14117648, 0.16470589, 0.1254902 ],\n",
              "          ...,\n",
              "          [0.1254902 , 0.15294118, 0.09019608],\n",
              "          [0.15686275, 0.18431373, 0.12156864],\n",
              "          [0.22352943, 0.2509804 , 0.18823531]],\n",
              " \n",
              "         [[0.0509804 , 0.0627451 , 0.01960784],\n",
              "          [0.07058824, 0.08235294, 0.03921569],\n",
              "          [0.04313726, 0.06666667, 0.02745098],\n",
              "          ...,\n",
              "          [0.05882353, 0.07058824, 0.04313726],\n",
              "          [0.01568628, 0.02352941, 0.00392157],\n",
              "          [0.02352941, 0.03137255, 0.01176471]],\n",
              " \n",
              "         [[0.07843138, 0.09411766, 0.03921569],\n",
              "          [0.        , 0.00784314, 0.        ],\n",
              "          [0.01568628, 0.03921569, 0.        ],\n",
              "          ...,\n",
              "          [0.09019608, 0.09803922, 0.09411766],\n",
              "          [0.01568628, 0.02352941, 0.01960784],\n",
              "          [0.06666667, 0.07450981, 0.07058824]]],\n",
              " \n",
              " \n",
              "        [[[0.04313726, 0.02745098, 0.08235294],\n",
              "          [0.08235294, 0.07058824, 0.10588236],\n",
              "          [0.        , 0.        , 0.00784314],\n",
              "          ...,\n",
              "          [0.02745098, 0.05882353, 0.00784314],\n",
              "          [0.00784314, 0.0509804 , 0.        ],\n",
              "          [0.03921569, 0.08235294, 0.01568628]],\n",
              " \n",
              "         [[0.04705883, 0.04705883, 0.07843138],\n",
              "          [0.04313726, 0.04705883, 0.0627451 ],\n",
              "          [0.01176471, 0.02745098, 0.02352941],\n",
              "          ...,\n",
              "          [0.01960784, 0.0509804 , 0.        ],\n",
              "          [0.01568628, 0.04705883, 0.        ],\n",
              "          [0.00392157, 0.04705883, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.03137255, 0.02745098],\n",
              "          [0.05882353, 0.09411766, 0.08235294],\n",
              "          [0.07450981, 0.1137255 , 0.07843138],\n",
              "          ...,\n",
              "          [0.06666667, 0.09019608, 0.04313726],\n",
              "          [0.07450981, 0.10588236, 0.04705883],\n",
              "          [0.02745098, 0.05882353, 0.        ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.14117648, 0.17254902, 0.12156864],\n",
              "          [0.18039216, 0.21176472, 0.16078432],\n",
              "          [0.18431373, 0.21568629, 0.16470589],\n",
              "          ...,\n",
              "          [0.03529412, 0.07843138, 0.04705883],\n",
              "          [0.08235294, 0.11764707, 0.09803922],\n",
              "          [0.21176472, 0.24705884, 0.227451  ]],\n",
              " \n",
              "         [[0.01568628, 0.03529412, 0.01960784],\n",
              "          [0.04705883, 0.06666667, 0.0509804 ],\n",
              "          [0.03529412, 0.05490196, 0.03137255],\n",
              "          ...,\n",
              "          [0.        , 0.02745098, 0.01568628],\n",
              "          [0.        , 0.00784314, 0.00392157],\n",
              "          [0.0627451 , 0.07843138, 0.08235294]],\n",
              " \n",
              "         [[0.03529412, 0.03921569, 0.04705883],\n",
              "          [0.03137255, 0.04705883, 0.0509804 ],\n",
              "          [0.01176471, 0.02745098, 0.02352941],\n",
              "          ...,\n",
              "          [0.04705883, 0.07058824, 0.0627451 ],\n",
              "          [0.00784314, 0.01176471, 0.01960784],\n",
              "          [0.03137255, 0.03529412, 0.0509804 ]]]], dtype=float32),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMUxWI-_V-C3",
        "colab_type": "text"
      },
      "source": [
        "## Instatiate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8gENxFLV-C3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        " \n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model # This is the functional API\n",
        " \n",
        "resnet = ResNet50(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guQRuLt-pHAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdhI29jJpgik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17d333c6-76a2-4665-e67a-0a32af9ac596"
      },
      "source": [
        "type(resnet)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.engine.training.Model"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf2VlONMpPR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x) # This layer is a really fancy flatten\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(resnet.input, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjpJwwAfphfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQ6tQwnV-C_",
        "colab_type": "text"
      },
      "source": [
        "## Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpJA3jovV-C_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f0c5d17f-5a2e-40cc-90c4-08bdeafd74ae"
      },
      "source": [
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 3s 101ms/step - loss: 0.8963 - accuracy: 0.5176 - val_loss: 0.9001 - val_accuracy: 0.3466\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.6241 - accuracy: 0.6327 - val_loss: 0.5511 - val_accuracy: 0.7914\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.5211 - accuracy: 0.7944 - val_loss: 0.5857 - val_accuracy: 0.7730\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.5052 - accuracy: 0.7625 - val_loss: 0.4820 - val_accuracy: 0.8160\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.4282 - accuracy: 0.8503 - val_loss: 0.4091 - val_accuracy: 0.8896\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.4290 - accuracy: 0.8044 - val_loss: 0.5630 - val_accuracy: 0.7239\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.3639 - accuracy: 0.8802 - val_loss: 0.3242 - val_accuracy: 0.9264\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.3496 - accuracy: 0.8862 - val_loss: 0.4497 - val_accuracy: 0.8344\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 3s 78ms/step - loss: 0.2949 - accuracy: 0.8942 - val_loss: 0.3768 - val_accuracy: 0.8344\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.2997 - accuracy: 0.9122 - val_loss: 0.2997 - val_accuracy: 0.9080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdrEJGtMrdZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb459cdc-8e23-4e9e-db43-b840ea58515c"
      },
      "source": [
        "val_data_gen[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[0.03529412, 0.04313726, 0.02352941],\n",
              "          [0.        , 0.01960784, 0.        ],\n",
              "          [0.03921569, 0.05882353, 0.04313726],\n",
              "          ...,\n",
              "          [0.04705883, 0.03921569, 0.04313726],\n",
              "          [0.04313726, 0.03529412, 0.03921569],\n",
              "          [0.02745098, 0.01960784, 0.02352941]],\n",
              " \n",
              "         [[0.        , 0.00784314, 0.        ],\n",
              "          [0.        , 0.01568628, 0.        ],\n",
              "          [0.        , 0.01568628, 0.        ],\n",
              "          ...,\n",
              "          [0.04705883, 0.03921569, 0.04313726],\n",
              "          [0.04313726, 0.03529412, 0.03921569],\n",
              "          [0.03529412, 0.02745098, 0.03137255]],\n",
              " \n",
              "         [[0.0627451 , 0.08627451, 0.04705883],\n",
              "          [0.12941177, 0.15294118, 0.1137255 ],\n",
              "          [0.10588236, 0.13725491, 0.09411766],\n",
              "          ...,\n",
              "          [0.        , 0.        , 0.        ],\n",
              "          [0.01960784, 0.01960784, 0.01960784],\n",
              "          [0.0627451 , 0.0627451 , 0.0627451 ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.05882353, 0.07450981, 0.08627451],\n",
              "          [0.02745098, 0.04313726, 0.05490196],\n",
              "          [0.07058824, 0.08627451, 0.09803922],\n",
              "          ...,\n",
              "          [0.07450981, 0.07843138, 0.05882353],\n",
              "          [0.18431373, 0.18823531, 0.16862746],\n",
              "          [0.2901961 , 0.2901961 , 0.28235295]],\n",
              " \n",
              "         [[0.        , 0.01176471, 0.03921569],\n",
              "          [0.00392157, 0.01568628, 0.03529412],\n",
              "          [0.03529412, 0.04705883, 0.06666667],\n",
              "          ...,\n",
              "          [0.07450981, 0.05882353, 0.05490196],\n",
              "          [0.05490196, 0.03137255, 0.03921569],\n",
              "          [0.01568628, 0.        , 0.        ]],\n",
              " \n",
              "         [[0.00784314, 0.01960784, 0.04705883],\n",
              "          [0.02352941, 0.03529412, 0.0627451 ],\n",
              "          [0.01960784, 0.03137255, 0.0509804 ],\n",
              "          ...,\n",
              "          [0.03529412, 0.        , 0.01176471],\n",
              "          [0.03137255, 0.        , 0.00784314],\n",
              "          [0.07058824, 0.03529412, 0.05490196]]],\n",
              " \n",
              " \n",
              "        [[[0.        , 0.10196079, 0.34901962],\n",
              "          [0.00392157, 0.1137255 , 0.36862746],\n",
              "          [0.01568628, 0.12941177, 0.39607847],\n",
              "          ...,\n",
              "          [0.1254902 , 0.227451  , 0.52156866],\n",
              "          [0.10980393, 0.21176472, 0.5058824 ],\n",
              "          [0.10196079, 0.20392159, 0.49803925]],\n",
              " \n",
              "         [[0.02745098, 0.13333334, 0.39607847],\n",
              "          [0.03921569, 0.14509805, 0.4156863 ],\n",
              "          [0.04313726, 0.15686275, 0.43137258],\n",
              "          ...,\n",
              "          [0.12941177, 0.23137257, 0.5254902 ],\n",
              "          [0.11764707, 0.21960786, 0.5137255 ],\n",
              "          [0.1137255 , 0.21568629, 0.50980395]],\n",
              " \n",
              "         [[0.01176471, 0.1137255 , 0.40784317],\n",
              "          [0.01960784, 0.12156864, 0.4156863 ],\n",
              "          [0.02352941, 0.1254902 , 0.41960788],\n",
              "          ...,\n",
              "          [0.13333334, 0.23529413, 0.5294118 ],\n",
              "          [0.1254902 , 0.227451  , 0.52156866],\n",
              "          [0.12156864, 0.22352943, 0.5176471 ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.7137255 , 0.70980394, 0.7411765 ],\n",
              "          [0.7254902 , 0.72156864, 0.75294125],\n",
              "          [0.7411765 , 0.7372549 , 0.7686275 ],\n",
              "          ...,\n",
              "          [0.69411767, 0.6862745 , 0.7372549 ],\n",
              "          [0.69411767, 0.6862745 , 0.7372549 ],\n",
              "          [0.69411767, 0.6862745 , 0.7372549 ]],\n",
              " \n",
              "         [[0.7176471 , 0.7137255 , 0.74509805],\n",
              "          [0.72156864, 0.7176471 , 0.7490196 ],\n",
              "          [0.72156864, 0.7176471 , 0.7490196 ],\n",
              "          ...,\n",
              "          [0.69411767, 0.6862745 , 0.7372549 ],\n",
              "          [0.7019608 , 0.69411767, 0.74509805],\n",
              "          [0.7058824 , 0.69803923, 0.7490196 ]],\n",
              " \n",
              "         [[0.7294118 , 0.7254902 , 0.7568628 ],\n",
              "          [0.7176471 , 0.7137255 , 0.74509805],\n",
              "          [0.70980394, 0.7058824 , 0.7372549 ],\n",
              "          ...,\n",
              "          [0.69411767, 0.6862745 , 0.7372549 ],\n",
              "          [0.7058824 , 0.69803923, 0.7490196 ],\n",
              "          [0.7137255 , 0.7058824 , 0.7568628 ]]],\n",
              " \n",
              " \n",
              "        [[[0.0627451 , 0.04705883, 0.03529412],\n",
              "          [0.03137255, 0.01568628, 0.00392157],\n",
              "          [0.02352941, 0.00784314, 0.        ],\n",
              "          ...,\n",
              "          [0.03137255, 0.04313726, 0.01568628],\n",
              "          [0.        , 0.00784314, 0.        ],\n",
              "          [0.03529412, 0.04705883, 0.01960784]],\n",
              " \n",
              "         [[0.01176471, 0.        , 0.        ],\n",
              "          [0.03137255, 0.01960784, 0.        ],\n",
              "          [0.04705883, 0.03529412, 0.        ],\n",
              "          ...,\n",
              "          [0.03137255, 0.03137255, 0.        ],\n",
              "          [0.01176471, 0.01176471, 0.        ],\n",
              "          [0.03137255, 0.03137255, 0.        ]],\n",
              " \n",
              "         [[0.21176472, 0.20000002, 0.14117648],\n",
              "          [0.14901961, 0.13725491, 0.07843138],\n",
              "          [0.11764707, 0.10588236, 0.04705883],\n",
              "          ...,\n",
              "          [0.14901961, 0.1254902 , 0.0627451 ],\n",
              "          [0.1137255 , 0.09411766, 0.01960784],\n",
              "          [0.15686275, 0.13725491, 0.0627451 ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.20784315, 0.20392159, 0.09411766],\n",
              "          [0.21960786, 0.21176472, 0.1137255 ],\n",
              "          [0.25882354, 0.2509804 , 0.16078432],\n",
              "          ...,\n",
              "          [0.23529413, 0.20784315, 0.13725491],\n",
              "          [0.2392157 , 0.21176472, 0.14117648],\n",
              "          [0.2784314 , 0.2509804 , 0.1764706 ]],\n",
              " \n",
              "         [[0.01568628, 0.00784314, 0.        ],\n",
              "          [0.04705883, 0.03529412, 0.        ],\n",
              "          [0.05882353, 0.04705883, 0.        ],\n",
              "          ...,\n",
              "          [0.08627451, 0.05490196, 0.04313726],\n",
              "          [0.04313726, 0.01568628, 0.        ],\n",
              "          [0.04313726, 0.01568628, 0.        ]],\n",
              " \n",
              "         [[0.04705883, 0.03529412, 0.        ],\n",
              "          [0.04705883, 0.03529412, 0.        ],\n",
              "          [0.01568628, 0.        , 0.        ],\n",
              "          ...,\n",
              "          [0.03529412, 0.01176471, 0.01960784],\n",
              "          [0.03529412, 0.01176471, 0.01960784],\n",
              "          [0.05490196, 0.03137255, 0.03137255]]],\n",
              " \n",
              " \n",
              "        ...,\n",
              " \n",
              " \n",
              "        [[[0.05882353, 0.3803922 , 0.80392164],\n",
              "          [0.05882353, 0.38431376, 0.8000001 ],\n",
              "          [0.0627451 , 0.38823533, 0.7960785 ],\n",
              "          ...,\n",
              "          [0.4784314 , 0.27450982, 0.18039216],\n",
              "          [0.34117648, 0.19607845, 0.08235294],\n",
              "          [0.41176474, 0.29803923, 0.18039216]],\n",
              " \n",
              "         [[0.0627451 , 0.37254903, 0.77647066],\n",
              "          [0.0627451 , 0.37254903, 0.7686275 ],\n",
              "          [0.05490196, 0.3803922 , 0.7568628 ],\n",
              "          ...,\n",
              "          [0.5254902 , 0.3254902 , 0.24313727],\n",
              "          [0.32941177, 0.18431373, 0.08235294],\n",
              "          [0.5294118 , 0.41176474, 0.3019608 ]],\n",
              " \n",
              "         [[0.07450981, 0.37254903, 0.7490196 ],\n",
              "          [0.05882353, 0.36862746, 0.7294118 ],\n",
              "          [0.05882353, 0.37254903, 0.72156864],\n",
              "          ...,\n",
              "          [0.4784314 , 0.29411766, 0.22352943],\n",
              "          [0.35686275, 0.21176472, 0.13725491],\n",
              "          [0.42352945, 0.30588236, 0.21176472]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.47450984, 0.28627452, 0.24705884],\n",
              "          [0.52156866, 0.33333334, 0.28627452],\n",
              "          [0.56078434, 0.37254903, 0.3254902 ],\n",
              "          ...,\n",
              "          [0.74509805, 0.57254905, 0.47450984],\n",
              "          [0.73333335, 0.5529412 , 0.46274513],\n",
              "          [0.7019608 , 0.52156866, 0.43137258]],\n",
              " \n",
              "         [[0.5686275 , 0.3803922 , 0.34117648],\n",
              "          [0.5764706 , 0.38823533, 0.34901962],\n",
              "          [0.54901963, 0.36078432, 0.32156864],\n",
              "          ...,\n",
              "          [0.68235296, 0.5176471 , 0.41960788],\n",
              "          [0.72156864, 0.5568628 , 0.45882356],\n",
              "          [0.69803923, 0.52156866, 0.43137258]],\n",
              " \n",
              "         [[0.5568628 , 0.36078432, 0.3254902 ],\n",
              "          [0.5294118 , 0.34117648, 0.3019608 ],\n",
              "          [0.47450984, 0.28627452, 0.24705884],\n",
              "          ...,\n",
              "          [0.7294118 , 0.5764706 , 0.46274513],\n",
              "          [0.6901961 , 0.5372549 , 0.42352945],\n",
              "          [0.654902  , 0.4901961 , 0.3921569 ]]],\n",
              " \n",
              " \n",
              "        [[[0.7137255 , 0.77647066, 0.83921576],\n",
              "          [0.7294118 , 0.7803922 , 0.8470589 ],\n",
              "          [0.7372549 , 0.7803922 , 0.85098046],\n",
              "          ...,\n",
              "          [0.05882353, 0.04705883, 0.12941177],\n",
              "          [0.0627451 , 0.0509804 , 0.13333334],\n",
              "          [0.06666667, 0.05490196, 0.13725491]],\n",
              " \n",
              "         [[0.69411767, 0.75294125, 0.8352942 ],\n",
              "          [0.7137255 , 0.7607844 , 0.8470589 ],\n",
              "          [0.7294118 , 0.7803922 , 0.854902  ],\n",
              "          ...,\n",
              "          [0.03529412, 0.02352941, 0.10588236],\n",
              "          [0.03921569, 0.02745098, 0.10980393],\n",
              "          [0.04313726, 0.03137255, 0.1137255 ]],\n",
              " \n",
              "         [[0.6627451 , 0.7254902 , 0.82745105],\n",
              "          [0.6784314 , 0.7411765 , 0.8431373 ],\n",
              "          [0.7019608 , 0.7568628 , 0.86274517],\n",
              "          ...,\n",
              "          [0.03529412, 0.02352941, 0.10588236],\n",
              "          [0.03921569, 0.02745098, 0.10980393],\n",
              "          [0.03921569, 0.02745098, 0.10980393]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.24313727, 0.17254902, 0.11764707],\n",
              "          [0.15686275, 0.08627451, 0.03137255],\n",
              "          [0.14117648, 0.07058824, 0.01568628],\n",
              "          ...,\n",
              "          [0.5019608 , 0.40000004, 0.4039216 ],\n",
              "          [0.5411765 , 0.44705886, 0.44705886],\n",
              "          [0.5372549 , 0.4431373 , 0.4431373 ]],\n",
              " \n",
              "         [[0.18823531, 0.12156864, 0.05882353],\n",
              "          [0.16470589, 0.09411766, 0.04705883],\n",
              "          [0.10196079, 0.03529412, 0.        ],\n",
              "          ...,\n",
              "          [0.54901963, 0.44705886, 0.45098042],\n",
              "          [0.70980394, 0.60784316, 0.61960787],\n",
              "          [0.5647059 , 0.46274513, 0.47450984]],\n",
              " \n",
              "         [[0.14901961, 0.08235294, 0.01960784],\n",
              "          [0.16470589, 0.10196079, 0.0509804 ],\n",
              "          [0.07058824, 0.00392157, 0.        ],\n",
              "          ...,\n",
              "          [0.43921572, 0.3372549 , 0.34117648],\n",
              "          [0.49803925, 0.39607847, 0.40784317],\n",
              "          [0.49803925, 0.3921569 , 0.41176474]]],\n",
              " \n",
              " \n",
              "        [[[0.14117648, 0.19607845, 0.38823533],\n",
              "          [0.14117648, 0.19607845, 0.38823533],\n",
              "          [0.14117648, 0.19607845, 0.38823533],\n",
              "          ...,\n",
              "          [0.09803922, 0.15294118, 0.32941177],\n",
              "          [0.09411766, 0.14901961, 0.3254902 ],\n",
              "          [0.09411766, 0.14901961, 0.3254902 ]],\n",
              " \n",
              "         [[0.14117648, 0.19607845, 0.38823533],\n",
              "          [0.14117648, 0.19607845, 0.38823533],\n",
              "          [0.14117648, 0.19607845, 0.38823533],\n",
              "          ...,\n",
              "          [0.09803922, 0.15294118, 0.32941177],\n",
              "          [0.09803922, 0.15294118, 0.32941177],\n",
              "          [0.09803922, 0.15294118, 0.32941177]],\n",
              " \n",
              "         [[0.14117648, 0.19607845, 0.38823533],\n",
              "          [0.14117648, 0.19607845, 0.38823533],\n",
              "          [0.14117648, 0.19607845, 0.38823533],\n",
              "          ...,\n",
              "          [0.09803922, 0.15294118, 0.32941177],\n",
              "          [0.09803922, 0.15294118, 0.32941177],\n",
              "          [0.09803922, 0.15294118, 0.32941177]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.1764706 , 0.18039216, 0.14901961],\n",
              "          [0.16470589, 0.16862746, 0.13725491],\n",
              "          [0.14117648, 0.14509805, 0.1137255 ],\n",
              "          ...,\n",
              "          [0.07058824, 0.10196079, 0.04313726],\n",
              "          [0.05882353, 0.09411766, 0.02745098],\n",
              "          [0.07843138, 0.1137255 , 0.03921569]],\n",
              " \n",
              "         [[0.1137255 , 0.11764707, 0.08627451],\n",
              "          [0.15686275, 0.16078432, 0.12941177],\n",
              "          [0.10588236, 0.10980393, 0.07843138],\n",
              "          ...,\n",
              "          [0.07843138, 0.12156864, 0.05882353],\n",
              "          [0.05882353, 0.09019608, 0.03137255],\n",
              "          [0.05882353, 0.09411766, 0.02745098]],\n",
              " \n",
              "         [[0.03921569, 0.04313726, 0.01960784],\n",
              "          [0.18823531, 0.19215688, 0.16862746],\n",
              "          [0.19215688, 0.19607845, 0.17254902],\n",
              "          ...,\n",
              "          [0.02352941, 0.06666667, 0.00392157],\n",
              "          [0.03921569, 0.07058824, 0.01176471],\n",
              "          [0.02352941, 0.05490196, 0.        ]]]], dtype=float32),\n",
              " array([0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lwh3h14V-DC",
        "colab_type": "text"
      },
      "source": [
        "# Custom CNN Model\n",
        "\n",
        "In this step, write and train your own convolutional neural network using Keras. You can use any architecture that suits you as long as it has at least one convolutional and one pooling layer at the beginning of the network - you can add more if you want. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pse47spXV-DH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44c0cc96-d546-4d5a-b5cf-64a3725c5073"
      },
      "source": [
        "# Define the Model\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBXNagEa8XxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fba3ad7c-514a-42ec-ba74-6470fd1a7dec"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000,28,28,1)\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIJrvRz09DDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX61SdpyV-DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile Model\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFd-yHKnV-DP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "af1b9373-e9c3-4c70-ba59-f16886f2b5ac"
      },
      "source": [
        "# Fit Model\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0042 - val_accuracy: 0.9986\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0043 - val_accuracy: 0.9986\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0040 - val_accuracy: 0.9989\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0042 - val_accuracy: 0.9987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1f5c243160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OkYrY47V-DS",
        "colab_type": "text"
      },
      "source": [
        "# Custom CNN Model with Image Manipulations\n",
        "\n",
        "To simulate an increase in a sample of image, you can apply image manipulation techniques: cropping, rotation, stretching, etc. Luckily Keras has some handy functions for us to apply these techniques to our mountain and forest example. Simply, you should be able to modify our image generator for the problem. Check out these resources to help you get started: \n",
        "\n",
        "1. [Keras `ImageGenerator` Class](https://keras.io/preprocessing/image/#imagedatagenerator-class)\n",
        "2. [Building a powerful image classifier with very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3cu9fyXV-DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# State Code for Image Manipulation Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "# Resources and Stretch Goals\n",
        "\n",
        "Stretch goals\n",
        "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
        "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
        "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
        "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
        "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
        "\n",
        "Resources\n",
        "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
        "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
        "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
        "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
        "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
      ]
    }
  ]
}